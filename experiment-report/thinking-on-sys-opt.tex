\section{对系统优化工作的感想}

系统软件是支撑起计算机软件系统，尤其是各种互联网应用系统重要基础设施。
对系统软件的优化是极端重要的一项工作，经过调查研究和缜密构思后对系统软件进行优化，
在推动学科发展的同时，还可以为相关工业界应用节省大量资源。
算法创新、优化软件结构以及使用新硬件或分布式来优化问题解决能力，虽然各有侧重，
但必须结合起来才能发挥最大的效能。

\subsection{新软件结构和新算法}

对软件进行性能优化，我认为大致由两个出发点：
一是从软件结构上入手，消除系统瓶颈，避免资源浪费；
二是从算法创新上入手，提高相同计算资源下的性能产出。
如果工作任务里面两者都有，我认为先解决结构性问题比较重要，
这样能够减少一些算法创新工作中的噪音。

本次考核文章\cite{qiu_frozenhot_2023}做的工作，我认为属于前者。
文中的系统管理开销会随着单机并发数量的提到而提高，是非常典型的并发场景下的问题，
一定是发生了某种 contention。
解决此类问题，我觉得唯一的大方向就是在保持并行规模的前提下，
减少线程间互相可见的操作。毕竟没有互操作就没有并发管理开销。
一方面，我想能不能把计算任务分区，让各执行单元自己完成一部分计算，事后再reduce到一起。
如早期分布式应用中的 Map-Reduce。或者线程池用的 Work-Stealing 队列。
另一方面，可以避免不必要的计算任务。算得少自然管理开销就小。
对于一个通用缓存的场景，第一种优化方法好像不太切合实际。
毕竟如果各线程由独立的工作集，
他们各自持有一个缓存就好了。

考核文章采取的主要方法是上述的第二种：
利用数据局部性特点，设置只读前端缓存来相应多数缓存请求，
进而达到避免不必要的计算，减少 lock contention 的目的。
只读缓存的更新时机的选取，也可由失配率来指导。

综合对该文章的学习和以往的经验，我认为从软件结构层面入手对系统进行优化
首先要对计算机各通用硬件和操作系统有深入的了解，
然后针对其中一些特点总结一些一般的方法。尤其是和访存有关的技巧。

消除软件结构性问题后，就可以通过新算法进行优化。
本人将算法分为两类：一类是静态的，其行为不受数据影响(比如LRU, LFU, FIFO .etc)；
一类是动态的，其行为会反应数据特点(涉及机器学习的算法等)。
一些工作利用机器学习的手段对缓存 Eviction 进行优化，就属于后者。
GL-Cache 的工作是通过引入群组化的学习，
改变学习粒度和对象，避免了一些问题\cite{yang_gl-cache_nodate}。
是一种结合软件结构和算法的优化工作。

\subsection{新应用场景和新硬件}

有关新硬件的应用据我了解主要还是一些为特定计算或存储任务准备的特殊化硬件，
比如针对一些特殊的AI相关的数学运算，通用GPU往往不能以宣称的性能执行计算。
可以使用FPGA来加速学习管线中一些特殊的计算任务\cite{nurvi_2020_fpga}。
存储方面，如NBJL的一项工作，
结合PM-NVM硬件以及LSM结构上的创新，对其写入性能作出了显著的优化\cite{he_flatlsm_2023}。
通过新硬件加持，可以提升单台主机对特定问题的解决能力。

根据我对当前新应用和技术的观察，
我认为目前大型应用对计算和存储的需求已经趋于中心化了——
对AI的训练需要计算集群，移动设备用户每天产生的巨量数据也只有大规模的数据中心才能存放。
分布式系统的优化工作对存储和计算都提出了新的要求。
如\cite{qiaolin_yu_caas-lsm_2024}提出的CaaS-LSM将LSM的Compaction过程与各LSM-KVS解耦，
作为一个微服务部署在计算节点上，
这样就解决了在集群上Compaction负载不均衡的问题，提高了集群的整体利用率。
综上，对新硬件或新软件的使用要考虑其在分布式环境中的情况。

分布式技术增强系统并行规模的同时，不经意间还实现了计算和存储的集中。
一个计算或数据中心中各节点在地理上各节点非常接近。
我觉得可以利用这一特点对为特定业务做有针对性的优化，
就像多个线程可以共享数据一样，
让一些分布式的应用系统在各个节点间给不同的请求共享一些计算成果。
这样在云服务本身提供的就不仅是算力和存储的横向拓展了。

\subsection{个人成长}

从个人角度来看，要想优化好系统
首先要深刻理解和掌握通用计算机体系结构和相关原理。
只有这样，面对不同的优化任务，才有能有切实可行的思路和想法，
甚至在写软件设计阶段就可以避免一些性能损失。
其次，要尽力掌握一些新技术，如容器，容器编排等分布式技术。
保证个人进步和行业发展方向相同。
对于研究人员，还应该具备扎实的数学和问题建模能力，
对一些参数化的问题，往往可以直接利用已有的数学模型完成优化工作。
像\cite{yang_gl-cache_nodate}
一样老练的建模需要事前就对数学模型有深入的理解和掌握，
这种能力不是短时间可以建立的。
