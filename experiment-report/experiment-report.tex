\maketitle

\begin{abstract}
    本实验分别实现了传统LRU淘汰算法在单线程以及单把锁的多线程版本，用于展示lock contention对性能的影响。
    另外实现了基于无锁队列和智能指针的近似LRU算法、
    类似于Redis方案的采样LRU算法。
    本实验分别对不同线程数量、不同缓存容量以及不同缓存访问行为三个角度出发对上述三种缓存进行性能测试。
    报告还介绍了本实验的三种缓存的部分实现细节以及其对性能的影响，最后还有本人对系统方向优化工作的感想。
    
    \textbf{关键字:}\quad LRU\quad 采样LRU\quad lock-free\quad 无锁队列\quad 并发编程
\end{abstract}

\section{实验报告}

\subsection{实验平台}

本实验设计中开发、性能测试均在具备以下软硬件的系统上进行：
\begin{itemize}
    \item Intel Core I7 8750H 2.20GHz $\sim$ 4.10GHz
    \item 16GB DDR4 2667MHz
    \item 192 KB L1d, 192 KB L1i, 1.5M L2, 9M L3
    \item Linux 6.6.47-gentoo-dist x86\_64 GNU/Linux
    \item gcc version 14.2.1 20240817 (Gentoo 14.2.1\_p20240817 p4)
\end{itemize}

实验采用xmake作为构建系统，
使用的与本实验主题相关的开源软件在参考文献中列出。
使用的其他软件请参见\verb|xmake.lua|文件。
报告本身使用 \LaTeX 编写。编译运行实验代码、编译本报告可通过以下命令完成：
\begin{verbatim}
git submodule update --recursive --remote --init
xmake f -m release; xmake -j 12; xmake r
\end{verbatim}

\subsection{实现细节}

所有实现中使用的Hash算法均为 MurmurHash3 中的x64版本，输出的是128位Hash值。
本实验对其输出的128位Hash值做\verb|h[0] ^ (h[1] << 1)|处理以适应所使用的HashMap对象的要求。
单线程版本的LRU缓存使用\verb|std::unordered_map|作为hash索引，
其他两个无锁LRU缓存使用\verb|libcuckoo::cuckoohash_map|作为hash索引。

\subsubsection{单线程/单把锁LRU缓存}

单线程LRU缓存(后称N方案，Na\"{i}ve-LRU)实现了严格的LRU淘汰算法，
直接使用STL \verb|std::list| 存储缓存数据.
在hash表中存储各节点对应迭代器。节点的提升操作使用如下代码实现 
\begin{verbatim}
m_cache_list.splice(m_cache_list.begin(), m_cache_list, it->second);
\end{verbatim}
其中 \verb|it->second| 是指向该链表节点的迭代器，该操作将它指向的节点的位置关系移动到
\verb|m_cache_list.begin()|之前，所包含的元素并不会发生移动或拷贝。

\subsubsection{无锁FIFO-Hybrid-LRU}

该算法使用两个无锁队列和Hash表实现（后称H方案, FIFO-Hybrid-LRU）。

该方案从设计到实现并不容易，迭代了数个版本。
本文最初设想实现一个无锁双链表来克服N方案中单把锁造成的竞争，
在尝试过程中发现，并无办法实现对两个内存位置原子地进行修改，即CAS2。
历史上确有工作在理论上倚靠CAS2操作实现无锁双链表。
除了使用CAS2的链表理论，还有为单链表增加前驱节点提示的类双链表方案，
因依赖这种没有保证的前驱提示来实现LRU，本文认为其行为不可预测性太大，遂未采用。
除了上述两种链表方案，还有一种方案每次新插入链表两个节点的方案:
数据节点的前驱为一Dummy节点，Dummy节点的后继为数据节点。
在本文的应用场景中，在hash表中存储对应数据节点的Dummy节点，
当要进行LRU Promotion 操作时删除该Dummy节点的后继节点，即数据节点。
在LRU的使用场景中，频繁的Promition会造成大量的垃圾Dummy节点，
且难以利用现有设施，因此本文考虑接下来要介绍的方案。

LRU中使用链表的根本目的是为了利用链表节点前驱后继关系表达LRU的 Promotion 和 Aging.
使用双链表是为了方便Promotion操作将节点从链表中分离，然后再插入链表前部。
除此之外，LRU场景下的双链表就像队列一样工作。
因此本文的方案是直接使用无锁队列代替双链表，入队的对象类型一智能指针，
并用hash表索引与该智能指针相关的数据。

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{pics/fifo-hybrid-lru.drawio.png}
    \caption{FIFO混合LRU缓存结构示意图}
    \label{fig:fifo-h}
\end{figure}

该方案中，将队中存放的智能指针置空实现类似于分离链表节点的操作，
与上文中介绍的Dummy节点链表一样，会造成空间浪费。
为了缓解这个问题，本实现引入FIFO淘汰算法与基于队列的LRU混合，如图\ref{fig:fifo-h}所示。
它在减少队列中空指针元素造成的空间浪费的同时，
提高扫描型访问\footnote{即缓存访问服从 Uniform 分布}的缓存命中率。

该方案中，FIFO-Policy 队列中直接存放指向LRU Element 的\verb|weak_ptr|，对应的\verb|shared_ptr|被hash表持有。
LRU Element 包含用户KV、指向指向Manager Block 的指针。
LRU-Policy 队列中存放指向 Manager Block 的智能指针，其字段如图所示。

访问缓存时，首先通过hash索引到对应 LRU Element 对象，
之后立即对其中的指向 Manager Block 的指针做原子 \verb|exchange(nullptr)| 操作
\footnote{实现中，所有原子操作遵循：读使用acquire内存序，写使用release内存序，exchange使用acq\_rel内存序}，
其返回值由两种结果：
\begin{enumerate}
    \item \verb|==nullptr| 表示该元素被 FIFO-Policy 队列管理， 无需提升;
    \item \verb|!=nullptr| 表示该元素被 LRU-Policy 队列管理，需要提升。
\end{enumerate}
上述\verb|exchange|操作只有一个线程会返回非空结果，该线程随即对其进行提升.
同一时刻访问该元素的其他线程只能看到空指针，便认为其无需提升.

成功\verb|exchange|到 Manager Block 指针的线程接下来将其指向 LRU Element 的指针字段原子地置空,
相当于链表LRU中将节点从链表中分离的操作。此后，该线程将被访问 LRU Element 对应的\verb|weak_ptr|
重新推入FIFO-Policy队列，至此完成提升操作。

插入新元素时有必要的话先淘汰一个旧元素，
然后将分配好的包含用户数据的LRU Element智能指针先插入到hash表，
入队FIFO-Policy Queue即可；
删除特定元素操作仅需要从hash表中删除对应元素即可，两个队列中引用对应LRU Element的\verb|weak_ptr|
不会阻碍用户数据所占内存的回收。

旧元素\textbf{淘汰操作}需从LRU-Policy Queue 中出队一个指向 Manager Block 的智能指针;
原子地 \verb|exchange(nullptr)| 该 Manager Block 中指向 LRU Element 的指针对象，
若返回值为 \verb|nullptr| 则说明对应元素要么被其他线程淘汰，要么当前 Manager Block 为提升操作产生的垃圾。
返回空指针的情况继续尝试前面描述的步骤，直到能够锁定一个 LRU Element.
进而获得对应元素的Key，从hash表中删除。

与其他两种方案不同的是：由于结合了两种算法，采用了两个无锁队列。
需要平衡两个队列的大小。
本文中的方案为用户配置固定比例，默认FIFO-Policy Queue占总容量的 $80\%$,
LRU-Policy Queue占总容量的$20\%$. 每次新增或者提升元素后，
需要触发一次平衡操作，若该比例失衡则从FIFO-Policy Queue出队元素，
入队LRU-Policy Queue, 直到比例恢复。

该方案的两个队列大小关系可动态地结合多个缓存指标进行学习，
这是一个优化的方向。但是从软件结构和算法上来看，
该方案逐渐趋同于 FrozenHot。后者从各个方面来看都要比本方案优秀太多。
作为实验报告，本文不再进一步探讨 FIFO-Hybrid-LRU 方案的优化空间。

\subsubsection{无锁采样近似LRU}

本实验复现了 Redis 中的采样LRU算法（后称S方案，Sampling-LRU），并为其添加了无锁并发支持。

为了支持随机采样，本实现实现了支持随机访问的对象池，
该对象池以块(chunk)为单位管理内存\footnote{块大小对齐到4K}，不保证内存的连续性。
采样算法随机给出的元素下标对应内存位置若未被分配，则返回一个空指针。
下游系统 Deallocate 操作将会把当前对象所占内存放入一个无锁队列中回收，
下次 Allocate 操作优先从回收队列中获取。

系统维护一个32位无符号整形变量作为LRU Clock，
每次对缓存的访问都会使得Clock 原子地增1来表示时间的变化。
每个缓存节点包含节点上次访问时刻，节点当前被采样状态等字段。
其中节点上次访问时刻为一个32位无符号整数，用于表达元素之间的新旧关系。
由于大致计算不同节点间的老旧关系并无需准确的数据，
因此对该字段的更新和读取以及对LRU Clock的访问全部使用 \verb|relaxed| 内存序，
以尽可能减少原子操作对性能的负面影响。

节点的\textbf{提升操作}将会给其上次访问时刻赋最新LRU Clock值，
相比前两种通过变化数据结构内部节点位置关系的方式，仅需要 \verb|relaxed|地原子修改一个内存位置。

\textbf{插入新节点}需要从对象池中申请一块内存，在上面构造后赋予当前访问时间，并插入到hash表中。
当空间不足时，执行采样算法选取若干待决定元素，从中选取距离本次访问最旧的对象淘汰。
采样通过服从均匀分布的随机整数生成器生成若干在区间$\allowbreak (0, \mbox{Number of cached})$
的整数作为采样下标，并通过该下标从对象池中获取该对象存储区域的指针。
采样算法对当前时刻分别与两个待决定对象的上次访问时刻做差并对两者进行比较来区分出两者的新旧关系。
通过对做差结果取模，可以消除溢出对数据带来的影响。

\subsection{实验设计}

本小节对上述LRU方案从命中率、吞吐量以及内存消耗三个维度进行性能测试。
并分析三种方案中并发管理占总时间消耗的比例。
其中命中率、吞吐量和内存消耗数据为同一次实验测得。
\textbf{若未特别注明，则默认缓存大小为总测试大小的1/10, 进行30次测试取平均值, 每次测试重置缓存。}
每次缓存失配罚执行\verb|_mm_pause()|50次。

\subsubsection{命中率}

\begin{figure}
    \subfigure[Na\"{i}ve-LRU Hit Ratio]{ 
        \includegraphics[width=0.3\textwidth]{pics/different_dist_on_naive.png}
    }
    \subfigure[FIFO-Hybrid-LRU Hit Ratio]{ 
        \includegraphics[width=0.3\textwidth]{pics/different_dist_on_queue.png}
    }
    \subfigure[Sampling-LRU Hit Ratio]{ 
        \includegraphics[width=0.3\textwidth]{pics/different_dist_on_sampling.png}
    }
    \caption{各LRU实现单线程下对两种访问类型模拟的命中率测试示意图}
    \label{fig:dist_on_3_1thread}
\end{figure}

首先对三个缓存实现在\textbf{单线程}下，
分别用 Zipfian 分布以及 Uniform 分布生成测试数据对它们进行测试。
测试结果如图\ref{fig:dist_on_3_1thread}所示，三者命中率差距较小。
两种无锁缓存方案命中率表现略逊于Na\"{i}ve方案。

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{pics/multi_threads_on_both_hitratio_latency.png}
    \caption{各方案在多线程下的Zipfian型缓存访问命中率}
    \label{fig:dist_multithread}
\end{figure}

由于并发方案为了并发性能在LRU原始理论的某些方面做了妥协和放松，
因此其并发条件下命中率也许随并发规模变化而变化。
如图\ref{fig:dist_multithread}所示，三种缓存方案多线程下对Zipfian类型访问命中率均维持在 $72\% \sim 75\%$ 以内，
与单线程下测试相近。
其中Na\"{i}ve和Sampling方案命中率稳定，分别保持在 $74.5\%$ 和 $74.7\%$左右。
而FIFO-Hybrid-LRU命中率在 $72.9\% \sim 73.3\%$ 之间浮动。
这种现象与两种队列大小比例相关。

\subsubsection{吞吐量}

\begin{figure}
    \centering
    \subfigure[吞吐量]{ 
        \includegraphics[width=0.45\textwidth]{pics/multi_threads_on_both_latency_throughput.png}
        \label{fig:throughput-sub1}
    }
    \subfigure[实验耗时]{ 
        \includegraphics[width=0.45\textwidth]{pics/multi_threads_on_both_latency_latency.png}
        \label{fig:throughput-sub2}
    }
    \caption{各方案在多线程下的Zipfian型缓存访问吞吐量和实验耗时}
    \label{fig:throughput}
\end{figure}

基如图\ref{fig:throughput}所示, 于上文描述的实验方法，得出三种LRU完成试验所耗时间$l(ms)$以及吞吐量$t(\mbox{\small MQPS})$, 
\begin{gather}
    l = l_{\mbox{\small hash query}} + l_{\mbox{\small promotion/balance}} + l_{\mbox{\small insertion}} + l_{\mbox{\small penalty}} \label{eq:latency}\\
    t = \frac{10^6}{l} \mbox{\small Q/ms} = \frac{1000}{l} \mbox{\small MQPS}
\end{gather}
其中\ref{fig:throughput-sub1}显示专为并发环境设计的两个LRU方案
其吞吐量随着线程数增加而增加，符合本次实验目标。
本实验实现的 FIFO-Hybrid-LRU 更胜一筹，原因有三：
\begin{enumerate}
    \item 其内部使用的无锁数据结构是经过开源社区检验的优秀实现;
    \item 该设计以命中率略差的代价为并发性能赢得了空间；
    \item Sampling-LRU 需要为每个元素实现类似锁的机制，
        以避免并发采样过程中发生元素删除或回收，
        除此以外相比Redis的节点内单线程实现，还有其他并发引入的管理开销。
\end{enumerate}
另外，作为基准对比，Na\"{i}ve 方案吞吐量在线程数 $\geq 2$ 后相对其他两个实现变化不大，
但总体还是随线程数增加而减小。
这一点从图\ref{fig:throughput-sub2}实验耗时上看更为明显。
值得注意的是，吞吐量计算过程中，实验所耗事件如等式\ref{eq:latency}所示： 
缓存失配，以及引发的罚时延迟都算入消耗时间内。

\subsubsection{内存和管理开销分析}


