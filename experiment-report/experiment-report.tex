\maketitle

\begin{abstract}
    本实验分别实现了传统LRU淘汰算法在单线程以及单把锁的多线程版本，用于展示lock contention对性能的影响。
    另外实现了基于无锁队列和智能指针的近似LRU算法、
    类似于Redis方案的采样LRU算法。
    本实验分别对不同线程数量、不同缓存容量以及不同缓存访问行为三个角度出发对上述三种缓存进行性能测试。
    报告还介绍了本实验的三种缓存的部分实现细节以及其对性能的影响，最后还有本人对系统方向优化工作的感想。
    
    \textbf{关键字:}\quad LRU\quad 采样LRU\quad lock-free\quad 无锁队列\quad 并发编程
\end{abstract}

\section{实验报告}

\subsection{实验平台}

本实验设计中开发、性能测试均在具备以下软硬件的系统上进行：
\begin{itemize}
    \item Intel Core I7 8750H 2.20GHz $\sim$ 4.10GHz
    \item 16GB DDR4 2667MHz
    \item 192 KB L1d, 192 KB L1i, 1.5M L2, 9M L3
    \item Linux 6.6.47-gentoo-dist x86\_64 GNU/Linux
    \item gcc version 14.2.1 20240817 (Gentoo 14.2.1\_p20240817 p4)
\end{itemize}

实验采用xmake作为构建系统，
使用的与本实验主题相关的开源软件在参考文献中列出。
使用的其他软件请参见\verb|xmake.lua|文件。
报告本身使用 \LaTeX 编写。编译运行实验代码、编译本报告可通过以下命令完成：
\begin{verbatim}
git submodule update --recursive --remote --init
xmake f -m release; xmake -j 12; xmake r
\end{verbatim}

\subsection{实现细节}

所有实现中使用的Hash算法均为 MurmurHash3 中的x64版本，输出的是128位Hash值。
本实验对其输出的128位Hash值做\verb|h[0] ^ (h[1] << 1)|处理以适应所使用的HashMap对象的要求。
单线程版本的LRU缓存使用\verb|std::unordered_map|作为hash索引，
其他两个无锁LRU缓存使用\verb|libcuckoo::cuckoohash_map|作为hash索引。

\subsubsection{单线程/单把锁LRU缓存}

单线程LRU缓存(后称N方案，Na\"{i}ve-LRU)实现了严格的LRU淘汰算法，
直接使用STL \verb|std::list| 存储缓存数据.
在hash表中存储各节点对应迭代器。节点的提升操作使用如下代码实现 
\begin{verbatim}
m_cache_list.splice(m_cache_list.begin(), m_cache_list, it->second);
\end{verbatim}
其中 \verb|it->second| 是指向该链表节点的迭代器，该操作将它指向的节点的位置关系移动到
\verb|m_cache_list.begin()|之前，所包含的元素并不会发生移动或拷贝。

\subsubsection{无锁FIFO-Hybrid-LRU}

该算法使用两个无锁队列和Hash表实现（后称H方案, FIFO-Hybrid-LRU）。

该方案从设计到实现并不容易，迭代了数个版本。
本文最初设想实现一个无锁双链表来克服N方案中单把锁造成的竞争，
在尝试过程中发现，并无办法实现对两个内存位置原子地进行修改，即CAS2。
历史上确有工作在理论上倚靠CAS2操作实现无锁双链表。
除了使用CAS2的链表理论，还有为单链表增加前驱节点提示的类双链表方案，
因依赖这种没有保证的前驱提示来实现LRU，本文认为其行为不可预测性太大，遂未采用。
除了上述两种链表方案，还有一种方案每次新插入链表两个节点的方案:
数据节点的前驱为一Dummy节点，Dummy节点的后继为数据节点。
在本文的应用场景中，在hash表中存储对应数据节点的Dummy节点，
当要进行LRU Promotion 操作时删除该Dummy节点的后继节点，即数据节点。
在LRU的使用场景中，频繁的Promition会造成大量的垃圾Dummy节点，
且难以利用现有设施，因此本文考虑接下来要介绍的方案。

LRU中使用链表的根本目的是为了利用链表节点前驱后继关系表达LRU的 Promotion 和 Aging.
使用双链表是为了方便Promotion操作将节点从链表中分离，然后再插入链表前部。
除此之外，LRU场景下的双链表就像队列一样工作。
因此本文的方案是直接使用无锁队列代替双链表，入队的对象类型一智能指针，
并用hash表索引与该智能指针相关的数据。

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{pics/fifo-hybrid-lru.drawio.png}
    \caption{FIFO混合LRU缓存结构示意图}
    \label{fig:fifo-h}
\end{figure}

该方案中，将队中存放的智能指针置空实现类似于分离链表节点的操作，
与上文中介绍的Dummy节点链表一样，会造成空间浪费。
为了缓解这个问题，本实现引入FIFO淘汰算法与基于队列的LRU混合，如图\ref{fig:fifo-h}所示。
它在减少队列中空指针元素造成的空间浪费的同时，
提高扫描型访问\footnote{即缓存访问服从 Uniform 分布}的缓存命中率。

该方案中，FIFO-Policy 队列中直接存放指向LRU Element 的\verb|weak_ptr|，对应的\verb|shared_ptr|被hash表持有。
LRU Element 包含用户KV、指向指向Manager Block 的指针。
LRU-Policy 队列中存放指向 Manager Block 的智能指针，其字段如图所示。

访问缓存时，首先通过hash索引到对应 LRU Element 对象，
之后立即对其中的指向 Manager Block 的指针做原子 \verb|exchange(nullptr)| 操作
\footnote{实现中，所有原子操作遵循：读使用acquire内存序，写使用release内存序，exchange使用acq\_rel内存序}，
其返回值由两种结果：
\begin{enumerate}
    \item \verb|==nullptr| 表示该元素被 FIFO-Policy 队列管理， 无需Promotion;
    \item \verb|!=nullptr| 表示该元素被 LRU-Policy 队列管理，需要Promotion。
\end{enumerate}
上述\verb|exchange|操作只有一个线程会返回非空结果，该线程随即对其进行Promotion.
同一时刻访问该元素的其他线程只能看到空指针，便认为其无需Promotion.

成功\verb|exchange|到 Manager Block 指针的线程接下来将其指向 LRU Element 的指针字段原子地置空,
相当于链表LRU中将节点从链表中分离的操作。此后，该线程将被访问 LRU Element 对应的\verb|weak_ptr|
重新推入FIFO-Policy队列，至此完成Promotion操作。

插入新元素时有必要的话先淘汰一个旧元素，
然后将分配好的包含用户数据的LRU Element智能指针先插入到hash表，
入队FIFO-Policy Queue即可；
删除特定元素操作仅需要从hash表中删除对应元素即可，两个队列中引用对应LRU Element的\verb|weak_ptr|
不会阻碍用户数据所占内存的回收。

旧元素\textbf{淘汰操作}需从LRU-Policy Queue 中出队一个指向 Manager Block 的智能指针;
原子地 \verb|exchange(nullptr)| 该 Manager Block 中指向 LRU Element 的指针对象，
若返回值为 \verb|nullptr| 则说明对应元素要么被其他线程淘汰，要么当前 Manager Block 为提升操作产生的垃圾。
返回空指针的情况继续尝试前面描述的步骤，直到能够锁定一个 LRU Element.
进而获得对应元素的Key，从hash表中删除。

与其他两种方案不同的是：由于采用了结合了两种算法，采用了两个无锁队列。
需要平衡两个队列的大小。
本文中的方案为用户配置固定比例，默认FIFO-Policy Queue占总容量的 $80\%$,
LRU-Policy Queue占总容量的$20\%$. 每次新增或者提升元素后，
需要触发一次平衡操作，若该比例失衡则从FIFO-Policy Queue出队元素，
入队LRU-Policy Queue, 直到比例恢复。

\subsubsection{无锁采样近似LRU}

本实验复现了 Redis 中的采样LRU算法（后称S方案，Sampling-LRU），并为其添加了无锁并发支持。

为了支持随机采样，本实现实现了支持随机访问的对象池，
该对象池以块(chunk)为单位管理内存\footnote{一个块通常为4096B}，不保证内存的连续性。
采样算法随机给出的元素下标对应内存位置若未被分配，则返回一个空指针。
下游系统 Deallocate 操作将会把当前对象所占内存放入一个无锁队列中回收，
下次 Allocate 操作优先从回收队列中获取。

系统维护一个32位无符号整形变量作为LRU Clock，
每次对缓存的访问都会使得Clock 原子地增1来表示时间的变化。
每个缓存节点包含节点上次访问时刻，节点当前被采样状态等字段。
其中节点上次访问时刻为一个32位无符号整数，用于表达元素之间的新旧关系。
由于大致计算不同节点间的老旧关系并无需准确的数据，
因此对该字段的更新和读取以及对LRU Clock的访问全部使用 \verb|relaxed| 内存序，
以尽可能减少原子操作对性能的负面影响。

节点的\textbf{提升操作}将会给其上次访问时刻赋最新LRU Clock值，
相比前两种通过变化数据结构内部节点位置关系的方式，仅需要 \verb|relaxed|地原子修改一个内存位置。

\textbf{插入新节点}需要从对象池中申请一块内存，在上面构造后赋予当前访问时间，并插入到hash表中。
当空间不足时，执行采样算法选取若干待决定元素，从中选取距离本次访问最旧的对象淘汰。
采样通过服从均匀分布的随机整数生成器生成若干在区间$\allowbreak (0, \mbox{Number of cached})$
的整数作为采样下标，并通过该下标从对象池中获取该对象存储区域的指针。
采样算法对当前时刻分别与两个待决定对象的上次访问时刻做差并对两者进行比较来区分出两者的新旧关系。
通过对做差结果取模，可以消除溢出对数据带来的影响。

\subsection{设计思路}

Q 方案的设计初衷是用无锁链表和无锁hash表达到免除锁的目的。
但是在实现过程中发现，双链表难以通过原子CAS操作在分离某节点时继续维持双链表关系，
要达到像单线程双链表一样的效果需要DCAS或CAS2\footnote{能原子地修改两个内存位置的CAS操作}操作，
但所有现代CPU均不支持该操作。
因此Q方案转而使用无锁队列和原子对象智能指针的配合。相对双链表LRU，Q方案为了并发性能对内存使用进行了\textbf{宽松}。
每次提升操作会遗留一个垃圾节点在队列中。

S 方案是在Redis采样LRU算法的基础上，对其增加并发支持。
该方案操作简洁，核心思想是\textbf{宽松}淘汰对象的选取准确性要求。
仅需要原子地修改一个上次访问时刻即可维护LRU信息，
且该原子操作对准确性要求不高，使用 \verb|relaxed|内存序即可。
相比之下维持对象间新旧关系造成的写放大效应理论上要小于上两种算法。

综上所述，除了N方案作为体现锁是多么邪恶的存在以外，另外两种方案均对LRU算法中某个步骤进行\textbf{宽松}。
追求的不再是微观上的准确，而是宏观上的大概率的准确。这一变化为无锁并发编程减少了许多负担。

\subsection{实验设计}

本小节对上述LRU方案从命中率、吞吐量以及内存消耗三个维度进行性能测试。
并分析三种方案中并发管理占总时间消耗的比例。
其中命中率、吞吐量和内存消耗数据为同一次实验测得，
便于后续讨论各种特征的相关性。
未特别注明，默认缓存大小为总测试大小的1/10.

\begin{figure}
    \subfigure[Na\"{i}ve-LRU Hit Ratio]{ 
        \includegraphics[width=0.3\textwidth]{pics/different_dist_on_naive.png}
    }
    \subfigure[FIFO-Hybrid-LRU Hit Ratio]{ 
        \includegraphics[width=0.3\textwidth]{pics/different_dist_on_queue.png}
    }
    \subfigure[Sampling-LRU Hit Ratio]{ 
        \includegraphics[width=0.3\textwidth]{pics/different_dist_on_sampling.png}
    }
    \caption{各LRU实现单线程下对两种访问类型模拟的命中率测试示意图}
    \label{fig:dist_on_3_1thread}
\end{figure}

\subsubsection{命中率}

首先对三个缓存实现在单线程下，分别用 Zipfian 分布以及 Uniform 分布生成测试数据对它们进行测试。
测试结果如图\ref{fig:dist_on_3_1thread}所示，三者命中率大致相同.





