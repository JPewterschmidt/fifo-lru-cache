\maketitle

\begin{abstract}
    本实验分别实现了传统LRU淘汰算法在单线程以及单把锁的多线程版本，用于展示lock contention对性能的影响。
    另外实现了基于无锁队列和智能指针的近似LRU算法、
    类似于Redis方案的采样LRU算法。
    本实验分别对不同线程数量、不同缓存容量以及不同缓存访问行为三个角度出发对上述三种缓存进行性能测试。
    报告还介绍了本实验的三种缓存的部分实现细节以及其对性能的影响，最后还有本人对系统方向优化工作的感想。
    
    \textbf{关键字:}\quad LRU\quad 采样LRU\quad lock-free\quad 无锁队列\quad 并发编程
\end{abstract}

\section{实验报告}

\subsection{实验平台}

本实验设计中开发、性能测试均在具备以下软硬件的系统上进行：
\begin{itemize}
    \item Intel Core I7 8750H 2.20GHz $\sim$ 4.10GHz
    \item 16GB DDR4 2667MHz
    \item 192 KB L1d, 192 KB L1i, 1.5M L2, 9M L3
    \item Linux 6.6.47-gentoo-dist x86\_64 GNU/Linux
    \item gcc version 14.2.1 20240817 (Gentoo 14.2.1\_p20240817 p4)
\end{itemize}

实验采用xmake作为构建系统，
使用的与本实验主题相关的开源软件在参考文献中列出。
使用的其他软件请参见\verb|xmake.lua|文件。
报告本身使用 \LaTeX 编写。编译运行实验代码、编译本报告可通过以下命令完成：
\begin{verbatim}
git submodule update --recursive --remote --init
xmake f -m release; xmake -j 12; xmake r
\end{verbatim}

\subsection{实现细节}

所有实现中使用的Hash算法均为 MurmurHash3 中的x64版本，输出的是128位Hash值。
本实验对其输出的128位Hash值做\verb|h[0] ^ (h[1] << 1)|处理以适应所使用的HashMap对象的要求。
单线程版本的LRU缓存使用\verb|std::unordered_map|作为hash索引，
其他两个无锁LRU缓存使用\verb|libcuckoo::cuckoohash_map|作为hash索引。

\subsubsection{单线程/单把锁LRU缓存}

单线程LRU缓存(后称N方案，Na\"{i}ve-LRU)实现了严格的LRU淘汰算法，
直接使用STL \verb|std::list| 存储缓存数据.
在hash表中存储各节点对应迭代器。节点的提升操作使用如下代码实现 
\begin{verbatim}
m_cache_list.splice(m_cache_list.begin(), m_cache_list, it->second);
\end{verbatim}
其中 \verb|it->second| 是指向该链表节点的迭代器，该操作将它指向的节点的位置关系移动到
\verb|m_cache_list.begin()|之前，所包含的元素并不会发生移动或拷贝。

\subsubsection{无锁队列近似LRU}

该算法使用一个无锁队列模拟LRU算法（后称Q方案Queue-LRU）。

LRU算法使用双链表是为了方便提升操作将节点从链表中任意位置分离，并重新插入链表头部。
本文最初希望实现一个基于原子操作的无锁双链表。
但在链表中部分离节点需要原子地修改两个指针，有工作提出使用CAS2操作实现这一功能。
但CAS2并没有任何一款现代CPU支持。

相比之下，单链表使用CAS操作即可维持其结构。但其只能向后遍历，
不能获取其前驱节点，则只能$O(n)$地分离一个节点。
有工作也提出在每个新插入的数据节点前搭配一个 dummy 节点，辅助实现$O(1)$分离操作。
但是这种方案在LRU的应用场景中会造成大量 dummy node 滞留在链表中。
且必须从头实现，不容易利用已有设施。

\begin{figure}[b]
    \centering
    \includegraphics[width=0.6\textwidth]{pics/queue-lru-overall.drawio.png}
    \caption{Queue-LRU 示意图}
    \label{fig:queue-lru-overall}
\end{figure}

再三权衡之后，本文使用一个无锁队列来实现LRU算法:
如图\ref{fig:queue-lru-overall}所示，
在新插入的节点直接入队，出队的节点作为淘汰节点。
以
\verb|shared_ptr<atomic<shared_ptr<lru_element>>>|
作为入队的元素类型，以
\verb|weak_ptr<atomic<shared_ptr<lru_element>>>|
作为hash索引对象的类型。

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{pics/queue-lru-promoted.drawio.png}
    \caption{Queue-LRU 某节点提升后示意图}
    \label{fig:queue-lru-promoted}
\end{figure}

如图\ref{fig:queue-lru-promoted}所示,
访问某节点，首先索引到对应节点的弱指针，进而\verb|atomic<shared_ptr>|指针。
执行\textbf{提升操作}则使用原子\verb|exchange|将\verb|shared_ptr<lru_element>|换出，
重新插入队头，最后更新索引。

\subsubsection{无锁采样近似LRU}

本实验复现了 Redis 中的采样LRU算法（后称S方案，Sampling-LRU），并为其添加了无锁并发支持。

为了支持随机采样，本实现实现了支持随机访问的对象池，
该对象池以块(chunk)为单位管理内存\footnote{一个块通常为4096B}，不保证内存的连续性。
采样算法随机给出的元素下标对应内存位置若未被分配，则返回一个空指针。
下游系统 Deallocate 操作将会把当前对象所占内存放入一个无锁队列中回收，
下次 Allocate 操作优先从回收队列中获取。

系统维护一个32位无符号整形变量作为LRU Clock，
每次对缓存的访问都会使得Clock 原子地增1来表示时间的变化。
每个缓存节点包含节点上次访问时刻，节点当前被采样状态等字段。
其中节点上次访问时刻为一个32位无符号整数，用于表达元素之间的新旧关系。
由于大致计算不同节点间的老旧关系并无需准确的数据，
因此对该字段的更新和读取以及对LRU Clock的访问全部使用 \verb|relaxed| 内存序，
以尽可能减少原子操作对性能的负面影响。

节点的\textbf{提升操作}将会给其上次访问时刻赋最新LRU Clock值，
相比前两种通过变化数据结构内部节点位置关系的方式，仅需要 \verb|relaxed|地原子修改一个内存位置。

\textbf{插入新节点}需要从对象池中申请一块内存，在上面构造后赋予当前访问时间，并插入到hash表中。
当空间不足时，执行采样算法选取若干待决定元素，从中选取距离本次访问最旧的对象淘汰。
采样通过服从均匀分布的随机整数生成器生成若干在区间$\allowbreak (0, \mbox{Number of cached})$
的整数作为采样下标，并通过该下标从对象池中获取该对象存储区域的指针。
采样算法对当前时刻分别与两个待决定对象的上次访问时刻做差并对两者进行比较来区分出两者的新旧关系。
通过对做差结果取模，可以消除溢出对数据带来的影响。

\subsection{设计思路}

Q 方案的设计初衷是用无锁链表和无锁hash表达到免除锁的目的。
但是在实现过程中发现，双链表难以通过原子CAS操作在分离某节点时继续维持双链表关系，
要达到像单线程双链表一样的效果需要DCAS或CAS2\footnote{能原子地修改两个内存位置的CAS操作}操作，
但所有现代CPU均不支持该操作。
因此Q方案转而使用无锁队列和原子对象智能指针的配合。相对双链表LRU，Q方案为了并发性能对内存使用进行了\textbf{宽松}。
每次提升操作会遗留一个垃圾节点在队列中。

S 方案是在Redis采样LRU算法的基础上，对其增加并发支持。
该方案操作简洁，核心思想是\textbf{宽松}淘汰对象的选取准确性要求。
仅需要原子地修改一个上次访问时刻即可维护LRU信息，
且该原子操作对准确性要求不高，使用 \verb|relaxed|内存序即可。
相比之下维持对象间新旧关系造成的写放大效应理论上要小于上两种算法。

综上所述，除了N方案作为体现锁是多么邪恶的存在以外，另外两种方案均对LRU算法中某个步骤进行\textbf{宽松}。
追求的不再是微观上的准确，而是宏观上的大概率的准确。这一变化为无锁并发编程减少了许多负担。

\subsection{实验设计}

本小节对上述LRU方案从命中率、吞吐量以及内存消耗三个维度进行性能测试。
并分析三种方案中并发管理占总时间消耗的比例。
其中命中率、吞吐量和内存消耗数据为同一次实验测得，
便于后续讨论各种特征的相关性。
未特别注明，默认缓存大小为总测试大小的1/10.

\begin{figure}
    \subfigure[Na\"{i}ve-LRU Hit Ratio]{ 
        \includegraphics[width=0.3\textwidth]{pics/different_dist_on_naive.png}
    }
    \subfigure[Queue-lru Hit Ratio]{ 
        \includegraphics[width=0.3\textwidth]{pics/different_dist_on_queue.png}
    }
    \subfigure[Sampling-lru Hit Ratio]{ 
        \includegraphics[width=0.3\textwidth]{pics/different_dist_on_sampling.png}
    }
    \caption{各LRU实现单线程下对两种访问类型模拟的命中率测试示意图}
    \label{fig:dist_on_3_1thread}
\end{figure}

\subsubsection{命中率}

首先对三个缓存实现在单线程下，分别用 Zipfian 分布以及 Uniform 分布生成测试数据对它们进行测试。
测试结果如图\ref{fig:dist_on_3_1thread}所示，三者命中率大致相同.





